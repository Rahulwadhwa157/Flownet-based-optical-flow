{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b01236",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ClementPinard/FlowNetPytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r FlowNetPytorch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2f9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from FlowNetPytorch.models.FlowNetS import FlowNetS  \n",
    "from FlowNetPytorch.models.FlowNetS import flownets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b78f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlowNetS(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv3_1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv4_1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv5_1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (conv6_1): Sequential(\n",
       "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv5): Sequential(\n",
       "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv4): Sequential(\n",
       "    (0): ConvTranspose2d(1026, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv3): Sequential(\n",
       "    (0): ConvTranspose2d(770, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (deconv2): Sequential(\n",
       "    (0): ConvTranspose2d(386, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  )\n",
       "  (predict_flow6): Conv2d(1024, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow5): Conv2d(1026, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow4): Conv2d(770, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow3): Conv2d(386, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (predict_flow2): Conv2d(194, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow6_to_5): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow5_to_4): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow4_to_3): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (upsampled_flow3_to_2): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "checkpoint_path='flownets_EPE1.951.pth.tar'\n",
    "net = flownets()\n",
    "state_dict = torch.load(checkpoint_path,map_location=torch.device('cpu'))\n",
    "net.load_state_dict(state_dict['state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dec7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8467b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from FlowNetPytorch import flow_transforms\n",
    "from FlowNetPytorch.util import flow2rgb\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "        flow_transforms.ArrayToTensor(),\n",
    "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c1861e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3eb96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        data_dir=Path(data_dir)\n",
    "       \n",
    "        self.frames = []\n",
    "        img_ext=['png', 'jpg', 'bmp', 'ppm']\n",
    "        \n",
    "        for ext in img_ext:\n",
    "            test_files = data_dir.files('*1.{}'.format(ext))\n",
    "            for file in test_files:\n",
    "                img_pair = file.parent / (file.stem[:-1] + '2.{}'.format(ext))\n",
    "                if img_pair.isfile():\n",
    "                    self.frames.append([file, img_pair])\n",
    "        \n",
    "\n",
    "                          \n",
    "        \n",
    "                       \n",
    "                   \n",
    "                    \n",
    "                   \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "   \n",
    "    def __getitem__(self, index):\n",
    "        xx=self.frames[index]\n",
    "        frame1 = cv2.imread(xx[0])\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        frame2 = cv2.imread(xx[1])\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "       \n",
    "        \n",
    "       \n",
    "        if self.transform is not None:\n",
    "            frame1 = self.transform(frame1)\n",
    "            frame2 = self.transform(frame2)\n",
    "            \n",
    "\n",
    "       \n",
    "        return frame1,frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd7b4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datset=ImageDataset('inference',input_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be7965ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(datset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c1ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    img1,img2=data\n",
    "    input_var = torch.cat((img1,img2),1)\n",
    "    \n",
    "    output = net(input_var)\n",
    "    \n",
    "    h,w=img1.size()[-2:]\n",
    "\n",
    "    output=F.interpolate(output, size=(h, w), mode='bicubic', align_corners=False)\n",
    "    \n",
    "    for k in range(output.shape[0]):\n",
    "        rgb_flow = flow2rgb(output[k],1)\n",
    "        to_save = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "        cv2.imwrite('rgb'+str(i)+'.jpg',to_save)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baa9eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point(image,t,x,y):\n",
    "    c,h,w=image.shape\n",
    "    if t>=0 and t<c and x>=0 and x<h and y>=0 and y<w:\n",
    "        return image[t][x][y]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd6a99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_x(image,t,x,y):\n",
    "    x1=0\n",
    "    x2=0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            x1+=get_point(image,t+i,x+1,y+j)\n",
    "            x2+=get_point(image,t+i,x,y+j)\n",
    "            \n",
    "    ans=(x1-x2)/4\n",
    "    return ans\n",
    "\n",
    "\n",
    "def grad_y(image,t,x,y):\n",
    "    x1=0\n",
    "    x2=0\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            x1+=get_point(image,t+i,x+j,y+1)\n",
    "            x2+=get_point(image,t+i,x+j,y)\n",
    "    \n",
    "    ans=(x1-x2)/4\n",
    "    return ans\n",
    "\n",
    "\n",
    "def grad_t(image,t,x,y):\n",
    "    x1=0\n",
    "    x2=0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            x1+=get_point(image,t+1,x+i,y+j)\n",
    "            x2+=get_point(image,t,x+i,y+j)\n",
    "  \n",
    "    ans=(x1-x2)/4\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "978b2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optical_flow(img1, img2, W):\n",
    "    \n",
    "    # opticalFlow calculates the displacements in X and Y directions i.e., (u,v)\n",
    "    # given two consecutive images varying with time\n",
    "\n",
    "    n, m = img1.shape\n",
    "    arr = torch.zeros((2, n, m))\n",
    "\n",
    "    w = W // 2\n",
    "\n",
    "    image = torch.zeros((2, n + 2 * w, m + 2 * w))\n",
    "\n",
    "    gx = torch.zeros((n + 2 * w, m + 2 * w))\n",
    "    gy = torch.zeros((n + 2 * w, m + 2 * w))\n",
    "\n",
    "    gt = torch.zeros((n + 2 * w, m + 2 * w))\n",
    "\n",
    "    for i in range(w, n + w):\n",
    "        for j in range(w, m + w):\n",
    "#             print(i,j)\n",
    "            image[0][i][j] = img1[i - w][j - w]\n",
    "            image[1][i][j] = img2[i - w][j - w]\n",
    "\n",
    "    for i in range(n + 2 * w):\n",
    "        for j in range(m + 2 * w):\n",
    "#             print(i,j)\n",
    "            gx[i][j] = grad_x(image, 0, i, j)  # calculating gradient\n",
    "            gy[i][j] = grad_y(image, 0, i, j)\n",
    "            gt[i][j] = grad_t(image, 0, i, j)\n",
    "\n",
    "    for i in range(w, n + w):\n",
    "        for j in range(w, m + w):\n",
    "\n",
    "            window_gx = gx[i - w:i + w + 1, j - w:j + w + 1]\n",
    "            window_gy = gy[i - w:i + w + 1, j - w:j + w + 1]\n",
    "\n",
    "            A = torch.vstack((window_gx.flatten(), window_gy.flatten())).T\n",
    "            b = -gt[i - w:i + w + 1, j - w:j + w + 1].flatten()\n",
    "\n",
    "            u = torch.matmul(torch.pinverse(A), b)\n",
    "\n",
    "            arr[0][i - w][j - w] = u[0]\n",
    "            arr[1][i - w][j - w] = u[1]\n",
    "\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9b23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "063824d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datset2=ImageDataset('inference')\n",
    "train_loader2 = DataLoader(datset2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae861986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader2, 0):\n",
    "    img1,img2=data\n",
    "    k,h,w,c=img1.shape\n",
    "\n",
    "    \n",
    "    for j in range(k):\n",
    "        image1=img1[j].numpy()\n",
    "        image2=img2[j].numpy()\n",
    "        image1=cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "        image2=cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "        image1=torch.from_numpy(image1)\n",
    "        image2=torch.from_numpy(image2)\n",
    "        output=optical_flow(image1,image2,3)\n",
    "        \n",
    "        \n",
    "        rgb_flow = flow2rgb(output,1)\n",
    "        to_save = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
    "        c1=i*k+j\n",
    "        cv2.imwrite('rgb_lucas'+str(c1)+'.jpg',to_save)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2b10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
